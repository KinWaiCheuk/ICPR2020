{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from onsets_and_frames import *\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_A = TensorDataset(torch.tensor([0,1]))\n",
    "dataset_B = TensorDataset(torch.tensor([91,92, 93, 94, 95]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_A = DataLoader(dataset_A, shuffle=False)\n",
    "loader_B = DataLoader(dataset_B, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([tensor([0])], [tensor([91])])\n",
      "([tensor([1])], [tensor([92])])\n",
      "([tensor([0])], [tensor([94])])\n",
      "([tensor([1])], [tensor([95])])\n",
      "([tensor([0])], [tensor([95])])\n",
      "([tensor([1])], [tensor([93])])\n",
      "([tensor([0])], [tensor([91])])\n",
      "([tensor([1])], [tensor([93])])\n",
      "([tensor([0])], [tensor([92])])\n",
      "([tensor([1])], [tensor([94])])\n",
      "([tensor([0])], [tensor([93])])\n",
      "([tensor([1])], [tensor([94])])\n",
      "([tensor([0])], [tensor([93])])\n",
      "([tensor([1])], [tensor([91])])\n",
      "([tensor([0])], [tensor([95])])\n",
      "([tensor([1])], [tensor([94])])\n",
      "([tensor([0])], [tensor([93])])\n",
      "([tensor([1])], [tensor([94])])\n",
      "([tensor([0])], [tensor([94])])\n",
      "([tensor([1])], [tensor([93])])\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    for i in zip(loader_A, loader_B):\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logdir = f'runs_AE/CQTbatch32_WNet_narrow_z_dsksize{ds_ksize}_dsstride_{ds_stride}_' + '-' + datetime.now().strftime('%y%m%d-%H%M%S')\n",
    "device = f'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "iterations = 500000\n",
    "resume_iteration = None\n",
    "checkpoint_interval = 1000\n",
    "train_on = 'MAPS'\n",
    "\n",
    "batch_size = 32\n",
    "sequence_length = 327680\n",
    "model_complexity = 48\n",
    "if torch.cuda.is_available() and torch.cuda.get_device_properties(torch.cuda.current_device()).total_memory < 10e9:\n",
    "    batch_size //= 2\n",
    "    sequence_length //= 2\n",
    "    print(f'Reducing batch size to {batch_size} and sequence_length to {sequence_length} to save memory')\n",
    "\n",
    "learning_rate = 0.0006\n",
    "learning_rate_decay_steps = 10000\n",
    "learning_rate_decay_rate = 0.98\n",
    "\n",
    "leave_one_out = None\n",
    "\n",
    "clip_gradient_norm = 3\n",
    "\n",
    "validation_length = sequence_length\n",
    "validation_interval = 500\n",
    "\n",
    "refresh = False\n",
    "train_groups, validation_groups = ['train'], ['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading group AkPnBcht: 100%|██████████| 30/30 [00:00<00:00, 370.88it/s]\n",
      "Loading group AkPnBsdf: 100%|██████████| 30/30 [00:00<00:00, 445.72it/s]\n",
      "Loading group AkPnCGdD:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 7 groups of MAPS at data/MAPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading group AkPnCGdD: 100%|██████████| 30/30 [00:00<00:00, 373.92it/s]\n",
      "Loading group AkPnStgb: 100%|██████████| 30/30 [00:00<00:00, 342.82it/s]\n",
      "Loading group SptkBGAm: 100%|██████████| 30/30 [00:00<00:00, 531.53it/s]\n",
      "Loading group SptkBGCl: 100%|██████████| 30/30 [00:00<00:00, 175.36it/s]\n",
      "Loading group StbgTGd2: 100%|██████████| 30/30 [00:00<00:00, 162.09it/s]\n",
      "Loading group train:   1%|          | 6/967 [00:00<00:17, 56.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1 group of MAESTRO at ../../MAESTRO/maestro-v2.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading group train: 100%|██████████| 967/967 [00:10<00:00, 34.45it/s] \n",
      "Loading group ENSTDkAm: 100%|██████████| 30/30 [00:00<00:00, 180.14it/s]\n",
      "Loading group ENSTDkCl:   0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 2 groups of MAPS at data/MAPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading group ENSTDkCl: 100%|██████████| 30/30 [00:00<00:00, 184.29it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = MAPS(groups=['AkPnBcht', 'AkPnBsdf', 'AkPnCGdD', 'AkPnStgb', 'SptkBGAm', 'SptkBGCl', 'StbgTGd2'], sequence_length=sequence_length, refresh=refresh)\n",
    "semi_data = MAESTRO(groups=train_groups, sequence_length=sequence_length)\n",
    "validation_dataset = MAPS(groups=['ENSTDkAm', 'ENSTDkCl'], sequence_length=validation_length, refresh=refresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size, shuffle=True, drop_last=True)\n",
    "semi_loader = DataLoader(semi_data, batch_size, shuffle=True, drop_last=True)\n",
    "valloader = DataLoader(validation_dataset, 4, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(semi_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa9a3d7c550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0,1,2]\n",
    "b = ['a','b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'a')\n",
      "(1, 'b')\n",
      "(2, 'a')\n"
     ]
    }
   ],
   "source": [
    "for i in zip(a,cycle(b)):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "semi_loss = torch.load('semi_loss.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = torch.load('losses.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7b77fb1b321d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlosses\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msemi_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": [
    "losses + semi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss/transcription': tensor(0.6983, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'loss/reconstruction': tensor(0.3037, device='cuda:0', grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: losses.get(k, 0) + semi_loss.get(k, 0) for k in set(losses) | set(semi_loss)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss/reconstruction': tensor(0.1518, device='cuda:0', requires_grad=True),\n",
       " 'loss/transcription': tensor(0.6983, device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss/reconstruction': tensor(0.1518, device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0020, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(losses.values()) + sum(semi_loss.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss/reconstruction': tensor(0.1518, device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semi_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('loss/reconstruction', tensor(0.1518, device='cuda:0', requires_grad=True)), ('loss/transcription', tensor(0.6983, device='cuda:0', requires_grad=True))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for semi_batch, batch in zip(semi_loader, cycle(loader)):\n",
    "    counter+=1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
